
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Variational Inference &#8212; My Machine Learning Notes</title>
    
  <link rel="stylesheet" href="../../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Variational Mixture of Gaussians" href="VariationalGMM.html" />
    <link rel="prev" title="Expectation Maximization" href="EMAlgorithm.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../index.html">
  
  
  <h1 class="site-logo" id="site-title">My Machine Learning Notes</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../Intro.html">
   Welcome to my technical space
  </a>
 </li>
</ul>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1 current active collapsible-parent">
  <a class="reference internal" href="DensityEstimation.html">
   Density Estimation
  </a>
  <ul class="current collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="LaplaceApproximation.html">
     The Laplace Approximation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="GaussianMixtureModels.html">
     Gaussian Mixture Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="EMAlgorithm.html">
     Expectation Maximization
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Variational Inference
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="VariationalGMM.html">
     Variational Mixture of Gaussians
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../DynamicalSystems/DynamicalSystems.html">
   Dynamical Systems
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../DynamicalSystems/LinearSystemIdentification_EM.html">
     Parameter Estimation for Linear Dynamical Systems
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/files/DensityEstimation/VariationalInference.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/chandrusuresh/MyNotes"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/chandrusuresh/MyNotes/issues/new?title=Issue%20on%20page%20%2Ffiles/DensityEstimation/VariationalInference.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/chandrusuresh/MyNotes/master?urlpath=tree/./(root)/files/DensityEstimation/VariationalInference.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#factorized-distributions">
   Factorized Distributions
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#example">
   Example
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#optimal-distribution-for-mu">
     Optimal distribution for
     <span class="math notranslate nohighlight">
      \(\mu\)
     </span>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#optimal-distribution-for-tau">
     Optimal distribution for
     <span class="math notranslate nohighlight">
      \(\tau\)
     </span>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#back-to-the-example">
   Back to the Example
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#references">
   References
  </a>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="variational-inference">
<h1>Variational Inference<a class="headerlink" href="#variational-inference" title="Permalink to this headline">¶</a></h1>
<p>For many models of practical interest, evaluating the posterior distribution will be intractable either because of the high dimensionality of the latent space or a complex form of the posterior distribution. For such cases, approximation schemes are handy in deriving a good lower or upper bound on the posterior distribution. The approximation schemes fall into 2 categories - deterministic and stochastic. Stochastic methods involve sampling while deterministic methods are based on analytical approximations to the posterior. In this section, we review variational approximations to the posterior.</p>
<p>Suppose we have a fully Bayesian model with a set of <span class="math notranslate nohighlight">\(N\)</span> observed variables <span class="math notranslate nohighlight">\(X = \{x_1,x_2,\ldots,x_N \}\)</span> and latent variables <span class="math notranslate nohighlight">\(Z = \{z_1,z_2,\ldots,z_N \}\)</span>. Assume our model specifies the joint distribution <span class="math notranslate nohighlight">\(p(X,Z)\)</span> and our goal is to find an approximation for the conditional <span class="math notranslate nohighlight">\(p(Z|X)\)</span> which enables us to make predictions on <span class="math notranslate nohighlight">\(X\)</span>. We can express the log marginal likelihood of the data as: <span class="math notranslate nohighlight">\( \log {p(X)} = \mathcal{L}(q) + KL(q||p) \)</span> where</p>
<div class="math notranslate nohighlight">
\[\begin{split} \begin{align} \mathcal{L}(q) &amp;= \int {q(Z) \log{\frac{p(X,Z)}{q(Z)}}dZ} \\
KL(q||p) &amp;= \int{q(Z) \log{\frac{p(Z|X)}{q(Z)}}dZ}\end{align}\end{split}\]</div>
<p>The variational inference proceeds by maximizing the lower bound <span class="math notranslate nohighlight">\(\mathcal{L}(q)\)</span> with respect to the distribution <span class="math notranslate nohighlight">\(q(Z)\)</span> which is equivalent to minimizing the KL divergence. The KL divergence is minimum (equals 0) when <span class="math notranslate nohighlight">\(q(Z) = p(Z|X)\)</span>. When the posterior <span class="math notranslate nohighlight">\(p(Z|X)\)</span> is intractable, we use a restricted family of distributions for <span class="math notranslate nohighlight">\(q(Z)\)</span> and then seek the member of the family that minimizes the KL divergence.</p>
<div class="section" id="factorized-distributions">
<h2>Factorized Distributions<a class="headerlink" href="#factorized-distributions" title="Permalink to this headline">¶</a></h2>
<p>We restrict the family of distributions that factorize the joint distribution over the latent variables i.e. <span class="math notranslate nohighlight">\(q(Z) = \prod_{i=1}^M q_i(Z_i)\)</span>
where <span class="math notranslate nohighlight">\(M\)</span> denotes the number of disjoint groups of latent variables.</p>
<div class="math notranslate nohighlight">
\[\begin{split} \begin{align} \mathcal{L}(q) &amp;= \int{q(Z) \log{\frac{p(X,Z)}{q(Z)}}dZ} \\
&amp;= \int{\prod_{i=1}^M q_i(Z) \Big( \log{p(X,Z)} - \log{q(Z)} \Big) dZ } \\
&amp;= \int{q_j \Bigg(\int{\log{p(X,Z)} \prod_{i\ne j}^M q_i dZ_i}\Bigg) dZ_j} - \int{q_j \log{q_j} dZ_j } + \text{const.} \\ 
&amp;= \int{q_j \log \tilde{p}(X,Z_j) dZ_j} - \int{q_j \log{q_j} dZ_j } + \text{const.} \end{align}\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(\tilde{p}(X,Z_j) = \mathbb{E}_{i\ne j}\left[ \log p(X,Z)\right] + \text{const.}\)</span> representing the expection with respect to the q distributions over all variables <span class="math notranslate nohighlight">\(z_i\)</span> for <span class="math notranslate nohighlight">\(i \ne j\)</span>.</p>
<p>Thus the lower bound <span class="math notranslate nohighlight">\(\mathcal{L}(q_j)\)</span> can be maximized by minimizing the KL divergence between <span class="math notranslate nohighlight">\(q_j(Z_j)\)</span> and <span class="math notranslate nohighlight">\(\tilde{p}(X,Z_j)\)</span>. Thus we obtain <span class="math notranslate nohighlight">\(\log{q_j^*(Z_j)} = \mathbb{E}_{i\ne j}\left[ \log p(X,Z)\right] + \text{const.}\)</span></p>
<p>We determine the optimal solution over all the <span class="math notranslate nohighlight">\(z_j\)</span> by initializing all the factors <span class="math notranslate nohighlight">\(q_j(Z_j)\)</span> and then cycling through the factors replacing each in turn with a revised estimate given the right hand side of the above equation. We can ignore the constant term as it serves to normalize the distribution. Convergence is guaranteed because the bound is convex with respect to each of the factors <span class="math notranslate nohighlight">\(q_j(Z_j)\)</span>.</p>
</div>
<div class="section" id="example">
<h2>Example<a class="headerlink" href="#example" title="Permalink to this headline">¶</a></h2>
<p>This is an example to demonstrate the variational approximation  and adapted from Figure 4.14 in [1]. This is also the same example used to demonstrate the Laplace approximation.</p>
<p>Suppose <span class="math notranslate nohighlight">\(p(z) \propto \sigma(20z+4) \exp{\left(\frac{-z^2}{2}\right)}\)</span> where <span class="math notranslate nohighlight">\(\sigma(\cdot)\)</span> is the sigmoid function. This form is very common in classification problems and serves as a good practical example.</p>
<p>This is a distribution on a scalar random variable <span class="math notranslate nohighlight">\(z\)</span> and we seek to approximate it with a Gaussian. The parameters for Gaussian distributions will be determined by variational approximation. To initialize, we introduce conjugate prior distributions for the mean <span class="math notranslate nohighlight">\(\mu\)</span> and precision <span class="math notranslate nohighlight">\(\tau\)</span> given by:</p>
<div class="math notranslate nohighlight">
\[\begin{split} \begin{align} p(\tau) &amp;= \text{Gam}(\tau|a_0,b_0) \\
p(\mu|\tau)  &amp;= \mathcal{N}(\mu|\mu_0,(\lambda_0 \tau)^{-1})\end{align}\end{split}\]</div>
<p>We assume the posterior <span class="math notranslate nohighlight">\(q(\mu,\tau)\)</span> factorizes as: <span class="math notranslate nohighlight">\(q(\mu,\tau) = q_{\mu}(\mu) \cdot q_{\tau}(\tau)\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split} \begin{align} \mathcal{L}(q) &amp;= \int{q(Z) \ln\left\{\frac{p(X,Z)}{q(Z)}\right\}dZ} \\
&amp;= \int{q_{\mu} q_{\tau} \ln\left\{\frac{p(X|\mu,\tau) \cdot p(\mu|\tau) \cdot p(\tau)}{q_{\mu} q_{\tau}}\right\}dZ}  \end{align}\end{split}\]</div>
<div class="section" id="optimal-distribution-for-mu">
<h3>Optimal distribution for <span class="math notranslate nohighlight">\(\mu\)</span><a class="headerlink" href="#optimal-distribution-for-mu" title="Permalink to this headline">¶</a></h3>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align}\Rightarrow \mathcal{L}(q_{\mu}) &amp;= \int{q_{\mu} \int{q_{\tau} \log{\left[p(X|\mu,\tau) \cdot p(\mu|\tau) \cdot p(\tau)\right]}d\tau } d\mu} - \int q_{\mu} \log{q_{\mu}} d\mu - \int q_{\tau} \log{q_{\tau}} d\tau\\ 
&amp;= \int{q_{\mu} \int{q_{\tau} \log{\left[p(X|\mu,\tau) \cdot p(\mu|\tau) \right] }d\tau} d\mu} - \int q_{\mu} \log{q_{\mu}} d\mu - \int q_{\tau} \log{q_{\tau}} d\tau + \int{q_{\mu} q_{\tau} \log{p(\tau)}}d\tau d\mu\\
&amp;= \int{q_{\mu} \int{q_{\tau} \log{\left[p(X|\mu,\tau) \cdot p(\mu|\tau) \right] }d\tau} d\mu} - \int q_{\mu} \log{q_{\mu}} d\mu + \text{const.}\end{align}\end{split}\]</div>
<p>The lower bound can be maximized by maximizing the right hand side. The right hand side is also the negative KL divergence <span class="math notranslate nohighlight">\( KL(q_{\mu}||\mathbb{E}_{\tau} \left[p(X|\mu,\tau) \cdot p(\mu|\tau)\right])\)</span></p>
<p>The factorized distribution assumption above implies that <span class="math notranslate nohighlight">\(p(\mu|\tau) = p(\mu)\)</span>, we can further simplify the above expression as follows:</p>
<div class="math notranslate nohighlight">
\[ \log q^*_{\mu} = \mathbb{E}_{\tau} \log \left[p(X|\mu,\tau) \cdot q(\mu) \right]) + \text{const.}  \]</div>
<p>The optimum factors can be obtained as follows:</p>
<div class="math notranslate nohighlight">
\[\begin{split} \begin{align} \log{q_{\mu}^*(\mu)} &amp;= \mathbb{E}_{\tau} \left[-\frac{\tau}{2} \sum_{n=1}^N (x_n-\mu)^2 - \frac{\lambda_0 \tau}{2} (\mu-\mu_0)^2  \right] + \text{const.} \\
&amp;= -\frac{\mathbb{E}(\tau)}{2} \left[ \sum_{n=1}^N (x_n-\mu)^2 + \lambda_0(\mu-\mu_0)^2\right] + \text{const.} \end{align}\end{split}\]</div>
<p>Notice that the expression is quadratic and therefore parameters of a Gaussian distribution can be determined by completing the square.</p>
<div class="math notranslate nohighlight">
\[\begin{split} \begin{align} \mu_N &amp;= \frac{\lambda_0 \mu_0 + N\bar{x}}{N + \lambda_0}\\
\lambda_N &amp;= (N+\lambda_0) \mathbb{E}(\tau)\end{align}\end{split}\]</div>
</div>
<div class="section" id="optimal-distribution-for-tau">
<h3>Optimal distribution for <span class="math notranslate nohighlight">\(\tau\)</span><a class="headerlink" href="#optimal-distribution-for-tau" title="Permalink to this headline">¶</a></h3>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align}\Rightarrow \mathcal{L}(q_{\tau}) &amp;= \int{q_{\tau} \int{q_{\mu} \log{\left[p(X|\mu,\tau) \cdot p(\mu|\tau) \cdot p(\tau)\right]}d\mu } d\tau} - \int q_{\mu} \log{q_{\mu}} d\mu - \int q_{\tau} \log{q_{\tau}} d\tau\\ 
&amp;= \int{q_{\tau} \int{q_{\mu} \log{\left[p(X|\mu,\tau) \cdot p(\mu|\tau) \cdot p(\tau) \right] }d\mu} d\tau} - \int q_{\tau} \log{q_{\tau}} d\tau - \int q_{\mu} \log{q_{\mu}} d\mu + \int{q_{\mu} q_{\tau} \log{p(\mu)}}d\tau d\mu\\
&amp;= \int{q_{\mu} \int{q_{\tau} \log{\left[p(X|\mu,\tau) \cdot p(\mu|\tau) \cdot p(\tau) \right] }d\mu} d\tau} - \int q_{\tau} \log{q_{\tau}} d\tau + \text{const.}\end{align}\end{split}\]</div>
<p>The lower bound can be maximized by maximizing the right hand side. The right hand side is also the negative KL divergence <span class="math notranslate nohighlight">\( KL(q_{\tau}||\mathbb{E}_{\mu} \left[p(X|\mu,\tau) \cdot p(\mu|\tau) \cdot p(\tau)\right])\)</span></p>
<p>From the factorized distribution assumption above, we can further simplify the above expression as follows:</p>
<div class="math notranslate nohighlight">
\[ \log q^*_{\tau} = \mathbb{E}_{\mu} \log \left[p(X|\mu,\tau) \cdot q(\mu) \cdot q(\tau)\right]) + \text{const.} \]</div>
<p>The optimum factors can be obtained as follows:</p>
<div class="math notranslate nohighlight">
\[\begin{split} \begin{align} \log{q_{\tau}^*} &amp;= \mathbb{E}_{\mu} \left[\frac{N}{2}\log{\tau} -\frac{\tau}{2} \sum_{n=1}^N (x_n-\mu)^2 - \frac{\lambda_0 \tau}{2} (\mu-\mu_0)^2  + (a_0-1)\log{\tau} - b \tau\right] + \text{const.} \\
&amp;= \frac{N}{2}\log{\tau} + (a_0-1)\log{\tau} - b \tau - \frac{\tau}{2} \mathbb{E}_{\mu}\left[ \sum_{n=1}^N (x_n-\mu)^2 + \lambda_0(\mu-\mu_0)^2\right] + \text{const.} \end{align}\end{split}\]</div>
<p>This implies that <span class="math notranslate nohighlight">\(q_{\tau}\)</span> is a Gamma distribution with parameters:</p>
<div class="math notranslate nohighlight">
\[\begin{split} \begin{align} a_N &amp;= a_0 + \frac{N}{2}\\
b_N &amp;= b_0 + \frac{1}{2}\mathbb{E}_{\mu}\left[ \sum_{n=1}^N (x_n-\mu)^2 + \lambda_0(\mu-\mu_0)^2\right] \\
&amp;= b_0 + \frac{\lambda_0 \mu_0^2}{2} + \frac{1}{2} \left[ \sum_{n=1}^N{x_n^2} - 2 (N\bar{x}+\lambda_0\mu_0) \mathbb{E}(\mu)+(N+\lambda_0)\mathbb{E}(\mu^2) \right]\end{align}\end{split}\]</div>
<p>We iterate on computing optimal values of <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\tau\)</span> till convergence to get the optimal parameters for the posterior distribution.</p>
</div>
</div>
<div class="section" id="back-to-the-example">
<h2>Back to the Example<a class="headerlink" href="#back-to-the-example" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">scipy.integrate</span> <span class="k">import</span> <span class="n">trapz</span><span class="p">,</span><span class="n">cumtrapz</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="k">import</span> <span class="n">norm</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="o">%</span><span class="k">matplotlib</span> inline

<span class="kn">from</span> <span class="nn">numpy.random</span> <span class="k">import</span> <span class="n">rand</span>

<span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">den</span> <span class="o">=</span> <span class="mf">1.0</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="mf">1.0</span><span class="o">/</span><span class="n">den</span>

<span class="k">def</span> <span class="nf">p_z</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">z</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span><span class="o">*</span><span class="n">sigmoid</span><span class="p">(</span><span class="mi">20</span><span class="o">*</span><span class="n">z</span><span class="o">+</span><span class="mi">4</span><span class="p">)</span>
    <span class="n">sum_p</span> <span class="o">=</span> <span class="n">trapz</span><span class="p">(</span><span class="n">p</span><span class="p">,</span><span class="n">z</span><span class="p">)</span> <span class="c1">## normalize for plotting</span>
    <span class="k">return</span> <span class="n">p</span><span class="p">,</span><span class="n">p</span><span class="o">/</span><span class="n">sum_p</span>

<span class="c1">## Laplace Approximation</span>
<span class="k">def</span> <span class="nf">findMode</span><span class="p">(</span><span class="n">z_init</span><span class="p">,</span><span class="n">max_iter</span> <span class="o">=</span> <span class="mi">25</span><span class="p">,</span><span class="n">tol</span> <span class="o">=</span> <span class="mf">1E-6</span><span class="p">):</span>
    <span class="nb">iter</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">z_next</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="s1">&#39;d&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">max</span>
    <span class="n">z_cur</span> <span class="o">=</span> <span class="n">z_init</span>
    <span class="k">while</span> <span class="p">(</span><span class="nb">iter</span> <span class="o">&lt;</span> <span class="n">max_iter</span> <span class="ow">and</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">z_next</span><span class="o">-</span><span class="n">z_cur</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">tol</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">iter</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">z_cur</span> <span class="o">=</span> <span class="n">z_next</span>
        <span class="n">y</span>     <span class="o">=</span> <span class="n">z_cur</span> <span class="o">-</span> <span class="mi">20</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">sigmoid</span><span class="p">(</span><span class="mi">20</span><span class="o">*</span><span class="n">z_cur</span><span class="o">+</span><span class="mi">4</span><span class="p">))</span>
        <span class="n">der_y</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">+</span> <span class="mi">400</span><span class="o">*</span><span class="n">sigmoid</span><span class="p">(</span><span class="mi">20</span><span class="o">*</span><span class="n">z_cur</span><span class="o">+</span><span class="mi">4</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">sigmoid</span><span class="p">(</span><span class="mi">20</span><span class="o">*</span><span class="n">z_cur</span><span class="o">+</span><span class="mi">4</span><span class="p">))</span>
        <span class="n">z_next</span> <span class="o">=</span> <span class="n">z_cur</span> <span class="o">-</span> <span class="n">y</span><span class="o">/</span><span class="n">der_y</span>
        <span class="nb">iter</span> <span class="o">=</span> <span class="nb">iter</span><span class="o">+</span><span class="mi">1</span>
    <span class="k">return</span> <span class="n">z_next</span>

<span class="k">def</span> <span class="nf">getHessian</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
    <span class="n">sig_x</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="mi">20</span><span class="o">*</span><span class="n">z</span><span class="o">+</span><span class="mi">4</span><span class="p">)</span>
    <span class="k">return</span> <span class="mi">400</span><span class="o">*</span><span class="n">sig_x</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">sig_x</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>

<span class="c1">## Variational Approximation</span>
<span class="k">def</span> <span class="nf">getMu</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">E_tau</span><span class="p">,</span><span class="n">mu0</span><span class="p">,</span><span class="n">lambda0</span><span class="p">):</span>
    <span class="n">N</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
    <span class="n">mu_N</span> <span class="o">=</span> <span class="p">(</span><span class="n">lambda0</span><span class="o">*</span><span class="n">mu0</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">X</span><span class="p">))</span><span class="o">/</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="n">lambda0</span><span class="p">)</span>
    <span class="n">lambda_N</span> <span class="o">=</span> <span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="n">lambda0</span><span class="p">)</span><span class="o">*</span><span class="n">E_tau</span>
    <span class="k">return</span> <span class="n">mu_N</span><span class="p">,</span><span class="n">lambda_N</span>

<span class="k">def</span> <span class="nf">getTau</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">mu_N</span><span class="p">,</span><span class="n">lambda_N</span><span class="p">,</span><span class="n">mu0</span><span class="p">,</span><span class="n">lambda0</span><span class="p">,</span><span class="n">a0</span><span class="p">,</span><span class="n">b0</span><span class="p">):</span>
    <span class="n">N</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
    <span class="n">a_N</span> <span class="o">=</span> <span class="n">a0</span> <span class="o">+</span> <span class="n">N</span><span class="o">/</span><span class="mi">2</span>
    <span class="n">b_N</span> <span class="o">=</span> <span class="n">b0</span> <span class="o">+</span> <span class="mf">0.5</span><span class="o">*</span><span class="n">lambda0</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">mu0</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.5</span><span class="o">*</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span> <span class="o">-</span> <span class="mi">2</span><span class="o">*</span><span class="n">mu_N</span><span class="o">*</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="n">lambda0</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">lambda_N</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">b_N</span> <span class="o">=</span> <span class="n">b_N</span> <span class="o">+</span> <span class="mf">0.5</span><span class="o">*</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="n">lambda0</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">lambda_N</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">mu_N</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">a_N</span><span class="p">,</span><span class="n">b_N</span>
    
<span class="k">def</span> <span class="nf">VariationalApproximation</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">mu0</span><span class="p">,</span><span class="n">lambda0</span><span class="p">,</span><span class="n">a0</span><span class="p">,</span><span class="n">b0</span><span class="p">,</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span><span class="n">tol</span><span class="o">=</span><span class="mf">1E-6</span><span class="p">):</span>
    <span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">E_tau</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">if</span> <span class="n">b0</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">E_tau</span> <span class="o">=</span> <span class="n">a0</span><span class="o">/</span><span class="n">b0</span>
    <span class="n">mu1</span> <span class="o">=</span> <span class="n">mu0</span>
    <span class="n">lambda1</span> <span class="o">=</span> <span class="n">lambda0</span>
    <span class="n">a1</span> <span class="o">=</span> <span class="n">a0</span>
    <span class="n">b1</span> <span class="o">=</span> <span class="n">b0</span>
    <span class="n">post_prob</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">while</span> <span class="n">count</span> <span class="o">&lt;</span> <span class="n">max_iter</span><span class="p">:</span>
        <span class="n">count</span> <span class="o">=</span> <span class="n">count</span><span class="o">+</span><span class="mi">1</span>
        <span class="n">mu_N</span><span class="p">,</span><span class="n">lambda_N</span> <span class="o">=</span> <span class="n">getMu</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">E_tau</span><span class="p">,</span><span class="n">mu0</span><span class="p">,</span><span class="n">lambda0</span><span class="p">)</span>
        <span class="n">a_N</span><span class="p">,</span><span class="n">b_N</span> <span class="o">=</span> <span class="n">getTau</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">mu_N</span><span class="p">,</span><span class="n">lambda_N</span><span class="p">,</span><span class="n">mu0</span><span class="p">,</span><span class="n">lambda0</span><span class="p">,</span><span class="n">a0</span><span class="p">,</span><span class="n">b0</span><span class="p">)</span>
        <span class="n">max_del</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">mu_N</span><span class="o">-</span><span class="n">mu1</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">lambda_N</span><span class="o">-</span><span class="n">lambda1</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">a_N</span><span class="o">-</span><span class="n">a1</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">b_N</span><span class="o">-</span><span class="n">b1</span><span class="p">)]))</span>
<span class="c1">#         print(count,max_del)</span>
        <span class="k">if</span> <span class="n">max_del</span> <span class="o">&lt;=</span> <span class="n">tol</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Converged after Iteration:&quot;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">count</span><span class="p">))</span>
            <span class="k">break</span>
        <span class="n">mu1</span> <span class="o">=</span> <span class="n">mu_N</span>
        <span class="n">lambda1</span> <span class="o">=</span> <span class="n">lambda_N</span>
        <span class="n">a1</span> <span class="o">=</span> <span class="n">a_N</span>
        <span class="n">b1</span> <span class="o">=</span> <span class="n">b_N</span>
        <span class="n">E_tau</span> <span class="o">=</span> <span class="n">a1</span><span class="o">/</span><span class="n">b1</span>
    <span class="k">return</span> <span class="n">mu_N</span><span class="p">,</span><span class="n">lambda_N</span><span class="p">,</span><span class="n">a_N</span><span class="p">,</span><span class="n">b_N</span>

<span class="k">def</span> <span class="nf">sampleData</span><span class="p">(</span><span class="n">z</span><span class="p">,</span><span class="n">pzn</span><span class="p">,</span><span class="n">N</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="p">,))</span>
    <span class="n">cdf</span> <span class="o">=</span> <span class="n">cumtrapz</span><span class="p">(</span><span class="n">pzn</span><span class="p">,</span><span class="n">z</span><span class="p">,</span><span class="n">initial</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
        <span class="n">rnd</span> <span class="o">=</span> <span class="n">rand</span><span class="p">()</span>
        <span class="n">dif</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">cdf</span><span class="o">-</span><span class="n">rnd</span><span class="p">)</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">dif</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">dif</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">z</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">10000</span><span class="p">)</span>
<span class="n">pz</span><span class="p">,</span><span class="n">pzn</span> <span class="o">=</span> <span class="n">p_z</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>

<span class="c1">## Get Laplace distribution</span>
<span class="n">z0</span> <span class="o">=</span> <span class="n">findMode</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">getHessian</span><span class="p">(</span><span class="n">z0</span><span class="p">)</span>
<span class="n">z0_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">z</span><span class="o">-</span><span class="n">z0</span><span class="p">)</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">z</span><span class="o">-</span><span class="n">z0</span><span class="p">)))[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">p_z0</span> <span class="o">=</span> <span class="n">pzn</span><span class="p">[</span><span class="n">z0_idx</span><span class="p">]</span>

<span class="c1">## Get approx Gaussian distribution</span>
<span class="n">q_z_laplace</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">z0</span><span class="p">,</span> <span class="mi">1</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">A</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">z_sample</span> <span class="o">=</span> <span class="n">sampleData</span><span class="p">(</span><span class="n">z</span><span class="p">,</span><span class="n">pzn</span><span class="p">,</span><span class="mi">10000</span><span class="p">)</span>
<span class="n">mu0</span><span class="o">=</span><span class="mi">0</span>
<span class="n">lambda0</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">a0</span><span class="o">=</span><span class="mi">0</span>
<span class="n">b0</span><span class="o">=</span><span class="mi">0</span>
<span class="n">mu_N</span><span class="p">,</span><span class="n">lambda_N</span><span class="p">,</span><span class="n">a_N</span><span class="p">,</span><span class="n">b_N</span> <span class="o">=</span> <span class="n">VariationalApproximation</span><span class="p">(</span><span class="n">z_sample</span><span class="p">,</span><span class="n">mu0</span><span class="p">,</span><span class="n">lambda0</span><span class="p">,</span><span class="n">a0</span><span class="p">,</span><span class="n">b0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;mu_opt     = &#39;</span><span class="p">,</span><span class="n">mu_N</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;lambda_opt = &#39;</span><span class="p">,</span><span class="n">lambda_N</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;a_opt      = &#39;</span><span class="p">,</span><span class="n">a_N</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;b_opt      = &#39;</span><span class="p">,</span><span class="n">b_N</span><span class="p">)</span>
<span class="n">q_z_va</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">mu_N</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">b_N</span><span class="o">/</span><span class="n">a_N</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Converged after Iteration:6
mu_opt     =  0.6845780578057805
lambda_opt =  23547.49539608471
a_opt      =  5000.0
b_opt      =  2123.36807626316
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span><span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">cla</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">z</span><span class="p">,</span><span class="n">pzn</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s2">&quot;orange&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">z</span><span class="p">,</span><span class="n">pzn</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span>
                 <span class="n">facecolor</span><span class="o">=</span><span class="s2">&quot;orange&quot;</span><span class="p">,</span> <span class="c1"># The fill color</span>
                 <span class="n">color</span><span class="o">=</span><span class="s1">&#39;orange&#39;</span><span class="p">,</span>       <span class="c1"># The outline color</span>
                 <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>          <span class="c1"># Transparency of the fill</span>
<span class="c1">#ax.axvline(x=z0)#,ylim=0,ymax=0.7)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">vlines</span><span class="p">(</span><span class="n">z0</span><span class="p">,</span> <span class="n">ymin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ymax</span><span class="o">=</span><span class="n">p_z0</span><span class="p">,</span><span class="n">linestyles</span><span class="o">=</span><span class="s1">&#39;dotted&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">z</span><span class="p">,</span><span class="n">q_z_laplace</span><span class="p">,</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">z</span><span class="p">,</span><span class="n">q_z_va</span><span class="p">,</span><span class="s1">&#39;g&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="mi">4</span><span class="p">]);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mf">0.8</span><span class="p">]);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mf">0.2</span><span class="p">,</span><span class="mf">0.4</span><span class="p">,</span><span class="mf">0.6</span><span class="p">,</span><span class="mf">0.8</span><span class="p">]);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;Original&#39;</span><span class="p">,</span><span class="s1">&#39;Laplace&#39;</span><span class="p">,</span><span class="s1">&#39;Variational&#39;</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Laplace &amp; Variational approximations&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/VariationalInference_12_0.png" src="../../_images/VariationalInference_12_0.png" />
</div>
</div>
</div>
<div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<ol class="simple">
<li><p>Bishop, Christopher M. 2006. Pattern Recognition and Machine Learning. Springer.</p></li>
</ol>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./files\DensityEstimation"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="EMAlgorithm.html" title="previous page">Expectation Maximization</a>
    <a class='right-next' id="next-link" href="VariationalGMM.html" title="next page">Variational Mixture of Gaussians</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Chandrasekar Sureshkumar<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../../_static/js/index.d3f166471bb80abb5163.js"></script>


    
  </body>
</html>