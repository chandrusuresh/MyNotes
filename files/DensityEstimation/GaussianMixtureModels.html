
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Gaussian Mixture Models &#8212; My Machine Learning Notes</title>
    
  <link rel="stylesheet" href="../../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Expectation Maximization" href="EMAlgorithm.html" />
    <link rel="prev" title="The Laplace Approximation" href="LaplaceApproximation.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../index.html">
  
  
  <h1 class="site-logo" id="site-title">My Machine Learning Notes</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../Intro.html">
   Welcome to my technical space
  </a>
 </li>
</ul>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1 current active collapsible-parent">
  <a class="reference internal" href="DensityEstimation.html">
   Density Estimation
  </a>
  <ul class="current collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="LaplaceApproximation.html">
     The Laplace Approximation
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Gaussian Mixture Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="EMAlgorithm.html">
     Expectation Maximization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="VariationalInference.html">
     Variational Inference
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="VariationalGMM.html">
     Variational Mixture of Gaussians
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../DynamicalSystems/DynamicalSystems.html">
   Dynamical Systems
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../DynamicalSystems/LinearSystemIdentification_EM.html">
     Parameter Estimation for Linear Dynamical Systems
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/files/DensityEstimation/GaussianMixtureModels.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/chandrusuresh/MyNotes"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/chandrusuresh/MyNotes/issues/new?title=Issue%20on%20page%20%2Ffiles/DensityEstimation/GaussianMixtureModels.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/chandrusuresh/MyNotes/master?urlpath=tree/./(root)/files/DensityEstimation/GaussianMixtureModels.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#theory">
   Theory
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#maximum-likelihood-approach">
     Maximum Likelihood Approach
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#expectation-maximization-for-gmm">
     Expectation Maximization for GMM
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#mle-of-mu">
       MLE of
       <span class="math notranslate nohighlight">
        \(\mu\)
       </span>
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#mle-of-sigma">
       MLE of
       <span class="math notranslate nohighlight">
        \(\Sigma\)
       </span>
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#mle-of-pi">
       MLE of
       <span class="math notranslate nohighlight">
        \(\pi\)
       </span>
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#example">
   Example
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#references">
   References
  </a>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="gaussian-mixture-models">
<h1>Gaussian Mixture Models<a class="headerlink" href="#gaussian-mixture-models" title="Permalink to this headline">¶</a></h1>
<p><img alt="Palmer Penguins" src="../../_images/lter_penguins.png" /></p>
<p>A Gaussian mixture model (GMM) is a density model where we combine a finite number of K Gaussian distributions <span class="math notranslate nohighlight">\(\mathcal{N}(x|\mu_k,\Sigma_k)\)</span> so that the probability density of a random variable <span class="math notranslate nohighlight">\(x\)</span> is expressed as:</p>
<div class="math notranslate nohighlight">
\[\begin{split} p(x|\theta) = \sum_{k=1}^K \pi_k \mathcal{N}(x|\mu_k,\Sigma_k) \\
0 \le \pi_k \le 1, \sum_{k=1}^{K}{\pi_k} = 1\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(\theta:=\{\mu_k,\Sigma_k,\pi_k:k=1,2,\dots,K\}\)</span> is the collection of all parameters of the model.</p>
<p>Mixture models allow relatively complex marginal distributions to be expressed interms of more tractable joint distributions over an expanded space by the inclusion of latent (or unobserved) variables. In addition to providing a framework for building complex probability distributions, mixture models can be used to cluster data.</p>
<div class="section" id="theory">
<h2>Theory<a class="headerlink" href="#theory" title="Permalink to this headline">¶</a></h2>
<p>In density estimation, we estimate data compactly using a density from a parametric family of distributions. Typically, a Gaussian, this choice might make for a poor approximation, in which case a more expressive model to consider would be mixture models.</p>
<p>Gaussian Mixture models have the advantage to</p>
<ul class="simple">
<li><p>enable multi-modal data representations with multiple clusters.</p></li>
<li><p>compute the parameters, <span class="math notranslate nohighlight">\(\theta\)</span> computed/learned from data via a maximum likelihood approach using the Expectation-Maximization algorithm.</p></li>
</ul>
<p>Given a dataset for random variable <span class="math notranslate nohighlight">\(x\)</span>, we introduce a <span class="math notranslate nohighlight">\(K\)</span> dimensional binary random variable <span class="math notranslate nohighlight">\(z\)</span> having a 1-of-<span class="math notranslate nohighlight">\(K\)</span> representation in which a particular element <span class="math notranslate nohighlight">\(z_k = 1\)</span>  with <span class="math notranslate nohighlight">\(z_i = 0 \text{ } \forall i\ne k\)</span> i.e., <span class="math notranslate nohighlight">\(\sum{z_k} = 1\)</span>.
The marginal distribution <span class="math notranslate nohighlight">\(p(z,x)\)</span> is defined as <span class="math notranslate nohighlight">\( p(z,x) = p(x|z)\cdot p(z)\)</span>.</p>
<p>If <span class="math notranslate nohighlight">\(p(z_k = 1) = \pi_k\)</span> and <span class="math notranslate nohighlight">\(p(x|z_k=1) = \mathcal{N}(x|\mu_k,\Sigma_k)\)</span> then, $<span class="math notranslate nohighlight">\(\begin{align} p(z) &amp;= \prod_{k=1}^K \pi_k^{z_k} \\
p(x|z) &amp;= \prod_{k=1}^K \Bigg(\mathcal{N}(x|\mu_k,\Sigma_k)\Bigg)^{z_k} \end{align}\)</span>$</p>
<p>The marginal distribution of <span class="math notranslate nohighlight">\(x\)</span> is therefore,</p>
<div class="math notranslate nohighlight">
\[ p(x) = \sum_z p(x,z) = \sum_z p(z) p(x|z) = \sum_{k=1}^K{\pi_k \mathcal{N}(x|\mu_k,\Sigma_k) }\]</div>
<div class="section" id="maximum-likelihood-approach">
<h3>Maximum Likelihood Approach<a class="headerlink" href="#maximum-likelihood-approach" title="Permalink to this headline">¶</a></h3>
<p>In the maximum likelihood (MLE) approach, we wish to model a dataset of observations <span class="math notranslate nohighlight">\(\{x_1,x_2,\dots,x_N\}\)</span> using a mixture of Gaussians. In the MLE approach, we seek to compute the parameters <span class="math notranslate nohighlight">\(\pi\)</span>,<span class="math notranslate nohighlight">\(\mu\)</span>,<span class="math notranslate nohighlight">\(\Sigma\)</span> of each of the <span class="math notranslate nohighlight">\(K\)</span> Gaussians per the graphical model below.</p>
<p><img alt="MLE Graphical Model" src="../../_images/GMM_MLE_GraphicalModel.png" /></p>
<p>The log-likelihood for the entire dataset is expressed as:</p>
<div class="math notranslate nohighlight">
\[ \ln{p(X|\pi,\mu,\Sigma)} = \sum_{n=1}^N {\ln {\Bigg(\sum_{k=1}^K {\pi_k \mathcal{N}(x|\mu_k,\Sigma_k)}\Bigg)}} \]</div>
<p>To determine the optimal MLE parameters, we seek to compute <span class="math notranslate nohighlight">\(\pi\)</span>,<span class="math notranslate nohighlight">\(\mu\)</span>,<span class="math notranslate nohighlight">\(\Sigma\)</span> which maximize the likelihood of the data. Note however that this term is intractable due to the presence of the summation inside the logarithm, so that the logarithm no longer directly acts on the Gaussians.</p>
</div>
<div class="section" id="expectation-maximization-for-gmm">
<h3>Expectation Maximization for GMM<a class="headerlink" href="#expectation-maximization-for-gmm" title="Permalink to this headline">¶</a></h3>
<p>An elegant and powerful method for finding MLE solutions for models with latent variables is the EM algorithm.</p>
<p>At maximum likelihood, the derivative of the log-likelihood w.r.t each of the parameters is zero.</p>
<div class="section" id="mle-of-mu">
<h4>MLE of <span class="math notranslate nohighlight">\(\mu\)</span><a class="headerlink" href="#mle-of-mu" title="Permalink to this headline">¶</a></h4>
<div class="math notranslate nohighlight">
\[\begin{split} \begin{align} 
0 &amp;= \frac{d}{d \mu_k} \ln{p(X|\pi,\mu,\Sigma)} \\
&amp;= -\sum_{n=1}^N {\frac{\pi_k \mathcal{N}(x_n|\mu_k,\Sigma_k)}{\sum_{k=1}^K {\pi_k \mathcal{N}(x|\mu_k,\Sigma_k)}}\Sigma_k (x_n - \mu_k)}\\
&amp;= -\sum_{n=1}^N{\gamma(z_{nk})\Sigma_k (x_n - \mu_k)}
\end{align}\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(\gamma(z_{nk}) = \frac{\pi_k \mathcal{N}(x_n|\mu_k,\Sigma_k)}{\sum_{k=1}^K {\pi_k \mathcal{N}(x|\mu_k,\Sigma_k)}}\)</span> defined as the <code class="docutils literal notranslate"><span class="pre">responsibility</span> <span class="pre">that</span> <span class="pre">component</span></code> <span class="math notranslate nohighlight">\(k\)</span> <code class="docutils literal notranslate"><span class="pre">takes</span> <span class="pre">for</span> <span class="pre">explaining</span> <span class="pre">the</span> <span class="pre">observation</span></code> <span class="math notranslate nohighlight">\(x\)</span>, i.e., <span class="math notranslate nohighlight">\(\gamma(z_{nk}) = p(z_k=1|x_n)\)</span> is the posterior probability of the latent variable.</p>
<p>The MLE estimate of <span class="math notranslate nohighlight">\(\mu_k\)</span> is therefore</p>
<div class="math notranslate nohighlight">
\[\mu_k = \frac{\sum_{n=1}^N{\gamma(z_{nk}) x_n}}{\sum_{n=1}^N{\gamma(z_{nk})}} = \frac{1}{N_k}\sum_{n=1}^N{\gamma(z_{nk}) x_n}\]</div>
<p>where <span class="math notranslate nohighlight">\(N_k = \sum_{n=1}^N{\gamma(z_{nk})}\)</span> is the effective number of points assigned to the cluster <span class="math notranslate nohighlight">\(k\)</span>.</p>
</div>
<div class="section" id="mle-of-sigma">
<h4>MLE of <span class="math notranslate nohighlight">\(\Sigma\)</span><a class="headerlink" href="#mle-of-sigma" title="Permalink to this headline">¶</a></h4>
<div class="math notranslate nohighlight">
\[\begin{split} \begin{align} 
0 &amp;= \frac{d}{d \Sigma_k} \ln{p(X|\pi,\mu,\Sigma)} \\
&amp;= \frac{d}{d \Sigma_k} |\Sigma_k| -\sum_{n=1}^N {\frac{\pi_k \mathcal{N}(x_n|\mu_k,\Sigma_k)}{\sum_{k=1}^K {\pi_k \mathcal{N}(x|\mu_k,\Sigma_k)}} (x_n - \mu_k)(x_n - \mu_k)^T}\\
&amp;= \Sigma_k -\sum_{n=1}^N{\gamma(z_{nk}) (x_n - \mu_k)(x_n - \mu_k)^T}
\end{align}\end{split}\]</div>
<p>Note that the <span class="math notranslate nohighlight">\( \frac{d}{dA} \ln{\left(\det{A}\right)^{-1}} = A\)</span>. More details on this identity can be found <a class="reference external" href="https://statisticaloddsandends.wordpress.com/2018/05/24/derivative-of-log-det-x/">here</a>.</p>
<p>The MLE estimate of <span class="math notranslate nohighlight">\(\Sigma_k\)</span> is therefore</p>
<div class="math notranslate nohighlight">
\[\Sigma_k = \frac{1}{N_k}\sum_{n=1}^N{\gamma(z_{nk}) (x_n - \mu_k)(x_n - \mu_k)^T}\]</div>
</div>
<div class="section" id="mle-of-pi">
<h4>MLE of <span class="math notranslate nohighlight">\(\pi\)</span><a class="headerlink" href="#mle-of-pi" title="Permalink to this headline">¶</a></h4>
<p>To compute the MLE of <span class="math notranslate nohighlight">\(\pi\)</span>, the constraint <span class="math notranslate nohighlight">\(\sum_k \pi_k = 1\)</span> has to be accounted for. This can be done with a lagrange multipler <span class="math notranslate nohighlight">\(\lambda\)</span> and maximizing the quantity <span class="math notranslate nohighlight">\(\ln{p(X|\pi,\mu,\Sigma)} + \lambda \sum_k{\pi_k} - 1\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split} \begin{align} 
0 &amp;= \frac{d}{d \pi_k} \Bigg(\ln{p(X|\pi,\mu,\Sigma)} + \lambda \sum_k{\pi_k} - 1 \Bigg)\\
&amp;= \sum_{n=1}^N {\frac{\mathcal{N}(x_n|\mu_k,\Sigma_k)}{\sum_{k=1}^K {\pi_k \mathcal{N}(x|\mu_k,\Sigma_k)}} + \lambda} \end{align} \end{split}\]</div>
<p>Multiplying both sides by <span class="math notranslate nohighlight">\(\pi_k\)</span> and summing over k,</p>
<div class="math notranslate nohighlight">
\[\begin{split} \begin{align} 0 &amp;= \sum_{n=1}^N {\sum_{k=1}^K{\frac{\pi_k \mathcal{N}(x_n|\mu_k,\Sigma_k)}{\sum_{k=1}^K {\pi_k \mathcal{N}(x|\mu_k,\Sigma_k)}}}} + \sum_{k=1}^K {\pi_k \lambda} \\
&amp;= \sum_{n=1}^N {N_k} + \lambda \\
\Rightarrow \lambda &amp;= -\sum_{n=1}^N {N_k} = -N
\end{align}\end{split}\]</div>
<p>Substituting for <span class="math notranslate nohighlight">\(\lambda\)</span> above, the MLE of <span class="math notranslate nohighlight">\(\pi_k\)</span> is derived as:</p>
<div class="math notranslate nohighlight">
\[\pi_k = \frac{N_k}{N}\]</div>
<p>The above solutions do not constitute a closed-form solution for the parameters of the mixture model because of the dependence of the responsibilities <span class="math notranslate nohighlight">\(\gamma(z_{nk})\)</span> on the same parameters. An iterative scheme of these steps constitutes the EM algorithm can be applied to solve for the parameters.</p>
<p>Each iteration of the EM algorithm involves two updates - <code class="docutils literal notranslate"><span class="pre">the</span> <span class="pre">E</span> <span class="pre">step</span> <span class="pre">and</span> <span class="pre">the</span> <span class="pre">M</span> <span class="pre">step</span></code>.</p>
<ul class="simple">
<li><p>In the <code class="docutils literal notranslate"><span class="pre">E</span> <span class="pre">step</span></code>, we use the current values of the parameters to evaluate the responsibilities.</p></li>
<li><p>In the <code class="docutils literal notranslate"><span class="pre">M</span> <span class="pre">step</span></code>, we maximize the parameters with respect to the responsibilities computed in the <code class="docutils literal notranslate"><span class="pre">E</span> <span class="pre">step</span></code>.</p></li>
</ul>
</div>
</div>
</div>
<div class="section" id="example">
<h2>Example<a class="headerlink" href="#example" title="Permalink to this headline">¶</a></h2>
<p>The palmer penguins dataset released by [4] and obtained from [5] is used as an example. Two features - Flipper Length &amp; Culmen Length are used as the features to cluster the dataset into the 3 categories of penguins - Adelie, Chinstrap and Gentoo. The dataset is plotted below.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">import</span> <span class="nn">io</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="k">import</span> <span class="n">multivariate_normal</span> <span class="k">as</span> <span class="n">gaussian</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib.image</span> <span class="k">as</span> <span class="nn">mpimg</span>
<span class="kn">from</span> <span class="nn">matplotlib.patches</span> <span class="k">import</span> <span class="n">Ellipse</span>
<span class="kn">import</span> <span class="nn">matplotlib.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>
<span class="kn">import</span> <span class="nn">matplotlib.colors</span> <span class="k">as</span> <span class="nn">mcolors</span>

<span class="k">def</span> <span class="nf">getCSV</span><span class="p">(</span><span class="n">url</span><span class="p">):</span>
    <span class="n">download</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span><span class="o">.</span><span class="n">content</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">io</span><span class="o">.</span><span class="n">StringIO</span><span class="p">(</span><span class="n">download</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)))</span>
    <span class="k">return</span> <span class="n">df</span>

<span class="n">file</span> <span class="o">=</span> <span class="s2">&quot;https://raw.githubusercontent.com/mcnakhaee/palmerpenguins/master/palmerpenguins/data/penguins-raw.csv&quot;</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">getCSV</span><span class="p">(</span><span class="n">file</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">txt_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Species&#39;</span><span class="p">])</span>
<span class="n">lbl</span> <span class="o">=</span> <span class="n">txt_labels</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">fig</span><span class="p">,</span><span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">df_data</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">txt_labels</span><span class="p">)</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">mpimg</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="s1">&#39;../../img/lter_penguins.png&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">color</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;tomato&#39;</span><span class="p">,</span><span class="s1">&#39;mediumorchid&#39;</span><span class="p">,</span><span class="s1">&#39;seagreen&#39;</span><span class="p">,</span><span class="s1">&#39;aqua&#39;</span><span class="p">,</span><span class="s1">&#39;black&#39;</span><span class="p">,</span><span class="s1">&#39;magenta&#39;</span><span class="p">]</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">lbl</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">txt_labels</span><span class="p">):</span>
    <span class="n">df_data</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Species&#39;</span><span class="p">]</span> <span class="o">==</span>  <span class="n">lbl</span><span class="p">]</span>
<span class="c1">#     print(df_data[i].columns)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">df_data</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;Flipper Length (mm)&#39;</span><span class="p">],</span><span class="n">df_data</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;Culmen Length (mm)&#39;</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
<span class="c1"># ax[1].axis(&#39;off&#39;)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Flipper Length&#39;</span><span class="p">);</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Culmen Length&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/GaussianMixtureModels_10_0.png" src="../../_images/GaussianMixtureModels_10_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## Number of classes</span>
<span class="n">K</span> <span class="o">=</span> <span class="mi">3</span><span class="c1">#len(txt_labels)</span>

<span class="n">flp_len</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Flipper Length (mm)&#39;</span><span class="p">])</span>
<span class="n">clm_len</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Culmen Length (mm)&#39;</span><span class="p">])</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Flipper Length (mm)&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">notna</span><span class="p">()]</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Culmen Length (mm)&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">notna</span><span class="p">()]</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">matrix</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Flipper Length (mm)&#39;</span><span class="p">],</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Culmen Length (mm)&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
<span class="c1"># print(data)</span>

<span class="n">x_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">flp_len</span><span class="p">,</span><span class="n">clm_len</span><span class="p">])</span>
<span class="n">d</span> <span class="o">=</span> <span class="n">data</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x_mean</span><span class="p">,(</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">cov</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">d</span><span class="p">,</span><span class="n">d</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="c1">## Init</span>
<span class="n">pi_init</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="n">K</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">K</span><span class="p">)]</span><span class="c1">#[float(df_i.shape[0])/float(df.shape[0]) for df_i in df_data]</span>
<span class="n">mu_init</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ravel</span><span class="p">(</span><span class="n">data</span><span class="p">[:,</span><span class="n">k</span><span class="p">])</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">K</span><span class="p">)]</span>
<span class="c1"># sigma_init = [np.eye(x_mean.shape[0]) for k in range(K)]</span>
<span class="n">sigma_init</span> <span class="o">=</span> <span class="p">[</span><span class="n">cov</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">K</span><span class="p">)]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">E_Step</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">pi</span><span class="p">,</span><span class="n">mu</span><span class="p">,</span><span class="n">sigma</span><span class="p">):</span>
    <span class="n">gamma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">K</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
        <span class="n">tot</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">K</span><span class="p">):</span>
            <span class="n">gamma</span><span class="p">[</span><span class="n">n</span><span class="p">,</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">pi</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">*</span><span class="n">gaussian</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="n">n</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">,</span><span class="n">mean</span><span class="o">=</span><span class="n">mu</span><span class="p">[</span><span class="n">k</span><span class="p">],</span><span class="n">cov</span><span class="o">=</span><span class="n">sigma</span><span class="p">[</span><span class="n">k</span><span class="p">])</span>
            <span class="n">tot</span> <span class="o">=</span> <span class="n">tot</span> <span class="o">+</span> <span class="n">gamma</span><span class="p">[</span><span class="n">n</span><span class="p">][</span><span class="n">k</span><span class="p">]</span>
        <span class="n">gamma</span><span class="p">[</span><span class="n">n</span><span class="p">,:]</span> <span class="o">=</span> <span class="n">gamma</span><span class="p">[</span><span class="n">n</span><span class="p">,:]</span><span class="o">/</span><span class="n">tot</span>
    <span class="k">return</span> <span class="n">gamma</span>

<span class="k">def</span> <span class="nf">M_step</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">gamma</span><span class="p">):</span>
    <span class="n">Nk</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">K</span><span class="p">)]</span>
    <span class="n">pi</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">K</span><span class="p">)]</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">K</span><span class="p">):</span>
        <span class="n">Nk</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">gamma</span><span class="p">[:,</span><span class="n">k</span><span class="p">])</span>
        <span class="n">pi</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">Nk</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">mu_mat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">gamma</span><span class="p">)</span><span class="o">/</span><span class="n">Nk</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">K</span><span class="p">):</span>
        <span class="n">mu</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">mu_mat</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="n">k</span><span class="p">],</span><span class="n">mu_mat</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="n">k</span><span class="p">]]))</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">K</span><span class="p">)]</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">K</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="n">del_x</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span><span class="n">n</span><span class="p">]</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">mu</span><span class="p">[</span><span class="n">k</span><span class="p">],(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">1</span><span class="p">))</span>
            <span class="n">cov</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">del_x</span><span class="p">,</span><span class="n">del_x</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
            <span class="n">sigma</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">sigma</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">+</span> <span class="n">gamma</span><span class="p">[</span><span class="n">n</span><span class="p">,</span><span class="n">k</span><span class="p">]</span><span class="o">/</span><span class="n">Nk</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">*</span><span class="n">cov</span>
    
    <span class="k">return</span> <span class="n">mu</span><span class="p">,</span><span class="n">sigma</span><span class="p">,</span><span class="n">pi</span>

<span class="k">def</span> <span class="nf">getLogLikelihood</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">pi</span><span class="p">,</span><span class="n">mu</span><span class="p">,</span><span class="n">sigma</span><span class="p">):</span>
    <span class="n">logLikelihood</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
        <span class="n">prob</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">K</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">det</span><span class="p">(</span><span class="n">sigma</span><span class="p">[</span><span class="n">k</span><span class="p">])</span> <span class="o">&lt;</span> <span class="mf">1E-6</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="n">sigma</span><span class="p">[</span><span class="n">k</span><span class="p">])</span>
                <span class="k">continue</span>
            <span class="n">prob</span> <span class="o">=</span> <span class="n">prob</span> <span class="o">+</span> <span class="n">pi</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">*</span><span class="n">gaussian</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="n">n</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">,</span><span class="n">mean</span><span class="o">=</span><span class="n">mu</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">,</span><span class="n">cov</span><span class="o">=</span><span class="n">sigma</span><span class="p">[</span><span class="n">k</span><span class="p">])</span>
        <span class="n">logLikelihood</span> <span class="o">=</span> <span class="n">logLikelihood</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">prob</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">logLikelihood</span>

<span class="k">def</span> <span class="nf">EM</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">pi0</span><span class="p">,</span><span class="n">mu0</span><span class="p">,</span><span class="n">sigma0</span><span class="p">,</span><span class="n">iter_max</span> <span class="o">=</span> <span class="mi">250</span><span class="p">,</span><span class="n">tol</span><span class="o">=</span><span class="mf">1E-6</span><span class="p">):</span>
    <span class="n">pi_curr</span> <span class="o">=</span> <span class="n">pi0</span>
    <span class="n">mu_curr</span> <span class="o">=</span> <span class="n">mu0</span>
    <span class="n">sigma_curr</span> <span class="o">=</span> <span class="n">sigma0</span>
    <span class="nb">iter</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">post_prob</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">pi</span> <span class="o">=</span> <span class="n">pi0</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="n">mu0</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="n">sigma0</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="k">while</span> <span class="nb">iter</span> <span class="o">&lt;</span> <span class="n">iter_max</span><span class="p">:</span>
        <span class="n">max_del</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="s1">&#39;f&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">min</span>
        <span class="nb">iter</span> <span class="o">=</span> <span class="nb">iter</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">gamma</span> <span class="o">=</span> <span class="n">E_Step</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">pi</span><span class="p">,</span><span class="n">mu</span><span class="p">,</span><span class="n">sigma</span><span class="p">)</span>
        <span class="n">mu1</span><span class="p">,</span><span class="n">sigma1</span><span class="p">,</span><span class="n">pi1</span> <span class="o">=</span> <span class="n">M_step</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">gamma</span><span class="p">)</span>
<span class="c1">#         print(pi)</span>
<span class="c1">#         print(mu)</span>
<span class="c1">#         print(sigma)</span>
        <span class="n">prob</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">mu</span><span class="p">)):</span>
            <span class="n">del_mu</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">mu</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">-</span><span class="n">mu1</span><span class="p">[</span><span class="n">k</span><span class="p">]))</span>
            <span class="n">del_pi</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">pi</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">-</span><span class="n">pi1</span><span class="p">[</span><span class="n">k</span><span class="p">]))</span>
            <span class="n">del_sig</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">sigma</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">-</span><span class="n">sigma1</span><span class="p">[</span><span class="n">k</span><span class="p">])))</span>
            <span class="n">max_del</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">max_del</span><span class="p">,</span><span class="nb">max</span><span class="p">(</span><span class="n">del_mu</span><span class="p">,</span><span class="nb">max</span><span class="p">(</span><span class="n">del_pi</span><span class="p">,</span><span class="n">del_sig</span><span class="p">)))</span>
        <span class="n">pi</span> <span class="o">=</span> <span class="n">pi1</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">mu</span> <span class="o">=</span> <span class="n">mu1</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">sigma</span> <span class="o">=</span> <span class="n">sigma1</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">pi_curr</span> <span class="o">=</span> <span class="n">pi</span>
        <span class="n">mu_curr</span> <span class="o">=</span> <span class="n">mu</span>
        <span class="n">sigma_curr</span> <span class="o">=</span> <span class="n">sigma</span>
        <span class="n">post_prob</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">getLogLikelihood</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">pi</span><span class="p">,</span><span class="n">mu</span><span class="p">,</span><span class="n">sigma</span><span class="p">))</span>
<span class="c1">#         print(iter,max_del)</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">max_del</span> <span class="o">&lt;=</span> <span class="n">tol</span><span class="p">):</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Converged after Iteration: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">iter</span><span class="p">))</span>
            <span class="k">break</span>
    
    <span class="k">return</span> <span class="n">mu</span><span class="p">,</span><span class="n">sigma</span><span class="p">,</span><span class="n">pi</span><span class="p">,</span><span class="n">post_prob</span>

<span class="k">def</span> <span class="nf">confidence_ellipse</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">cov</span><span class="p">,</span> <span class="n">n_std</span><span class="o">=</span><span class="mf">3.0</span><span class="p">,</span> <span class="n">facecolor</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create a plot of the covariance confidence ellipse of `x` and `y`</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    cov : Covariance matrix</span>
<span class="sd">        Input data.</span>

<span class="sd">    ax : matplotlib.axes.Axes</span>
<span class="sd">        The axes object to draw the ellipse into.</span>

<span class="sd">    n_std : float</span>
<span class="sd">        The number of standard deviations to determine the ellipse&#39;s radiuses.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    matplotlib.patches.Ellipse</span>

<span class="sd">    Other parameters</span>
<span class="sd">    ----------------</span>
<span class="sd">    kwargs : `~matplotlib.patches.Patch` properties</span>
<span class="sd">    &quot;&quot;&quot;</span>
<span class="c1">#     if cov != cov.T:</span>
<span class="c1">#         raise ValueError(&quot;Not a valid covariance matrix&quot;)</span>

<span class="c1">#     cov = np.cov(x, y)</span>
    <span class="n">pearson</span> <span class="o">=</span> <span class="n">cov</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">cov</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">cov</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="c1"># Using a special case to obtain the eigenvalues of this</span>
    <span class="c1"># two-dimensionl dataset.</span>
    <span class="n">ell_radius_x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">pearson</span><span class="p">)</span>
    <span class="n">ell_radius_y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">pearson</span><span class="p">)</span>
    <span class="n">ellipse</span> <span class="o">=</span> <span class="n">Ellipse</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
        <span class="n">width</span><span class="o">=</span><span class="n">ell_radius_x</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span>
        <span class="n">height</span><span class="o">=</span><span class="n">ell_radius_y</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span>
        <span class="n">facecolor</span><span class="o">=</span><span class="n">facecolor</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="c1"># Calculating the stdandard deviation of x from</span>
    <span class="c1"># the squareroot of the variance and multiplying</span>
    <span class="c1"># with the given number of standard deviations.</span>
    <span class="n">scale_x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">cov</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span> <span class="o">*</span> <span class="n">n_std</span>
    <span class="n">mean_x</span> <span class="o">=</span> <span class="n">mu</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1"># calculating the stdandard deviation of y ...</span>
    <span class="n">scale_y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">cov</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span> <span class="o">*</span> <span class="n">n_std</span>
    <span class="n">mean_y</span> <span class="o">=</span> <span class="n">mu</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

    <span class="n">transf</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Affine2D</span><span class="p">()</span> \
        <span class="o">.</span><span class="n">rotate_deg</span><span class="p">(</span><span class="mi">45</span><span class="p">)</span> \
        <span class="o">.</span><span class="n">scale</span><span class="p">(</span><span class="n">scale_x</span><span class="p">,</span> <span class="n">scale_y</span><span class="p">)</span> \
        <span class="o">.</span><span class="n">translate</span><span class="p">(</span><span class="n">mean_x</span><span class="p">,</span> <span class="n">mean_y</span><span class="p">)</span>

    <span class="n">ellipse</span><span class="o">.</span><span class="n">set_transform</span><span class="p">(</span><span class="n">transf</span> <span class="o">+</span> <span class="n">ax</span><span class="o">.</span><span class="n">transData</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ax</span><span class="o">.</span><span class="n">add_patch</span><span class="p">(</span><span class="n">ellipse</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mu</span><span class="p">,</span><span class="n">sigma</span><span class="p">,</span><span class="n">pi</span><span class="p">,</span><span class="n">post_prob</span> <span class="o">=</span> <span class="n">EM</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="n">pi_init</span><span class="p">,</span><span class="n">mu_init</span><span class="p">,</span><span class="n">sigma_init</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Converged after Iteration: 110
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span><span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">gamma</span> <span class="o">=</span> <span class="n">E_Step</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="n">pi</span><span class="p">,</span><span class="n">mu</span><span class="p">,</span><span class="n">sigma</span><span class="p">)</span>
<span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
    <span class="n">rgb</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">K</span><span class="p">):</span>
        <span class="n">rgb</span> <span class="o">=</span> <span class="n">rgb</span><span class="o">+</span><span class="n">gamma</span><span class="p">[</span><span class="n">n</span><span class="p">,</span><span class="n">k</span><span class="p">]</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">mcolors</span><span class="o">.</span><span class="n">to_rgb</span><span class="p">(</span><span class="n">color</span><span class="p">[</span><span class="n">k</span><span class="p">]))</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="n">n</span><span class="p">],</span><span class="n">data</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="n">n</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="n">rgb</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Classification as a function of responsibilities&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">K</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">k</span> <span class="o">&lt;</span> <span class="mi">3</span><span class="p">:</span>
        <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">df_data</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="s1">&#39;Flipper Length (mm)&#39;</span><span class="p">],</span><span class="n">df_data</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="s1">&#39;Culmen Length (mm)&#39;</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">[</span><span class="n">k</span><span class="p">])</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">mu</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span><span class="n">mu</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span><span class="s1">&#39;kx&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
        <span class="n">confidence_ellipse</span><span class="p">(</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">mu</span><span class="p">[</span><span class="n">k</span><span class="p">],</span><span class="n">sigma</span><span class="p">[</span><span class="n">k</span><span class="p">],</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="n">edgecolor</span><span class="o">=</span><span class="n">color</span><span class="p">[</span><span class="n">k</span><span class="p">],</span><span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;dashed&#39;</span><span class="p">)</span>
        
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Confidence bounds of the clusters from EM&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Flipper Length (mm)&#39;</span><span class="p">);</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Culmen Length (mm)&#39;</span><span class="p">);</span>

<span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">post_prob</span><span class="p">)),</span><span class="n">post_prob</span><span class="p">);</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Learning curve&#39;</span><span class="p">);</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Log Likehood&#39;</span><span class="p">);</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Iteration Number&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/GaussianMixtureModels_14_0.png" src="../../_images/GaussianMixtureModels_14_0.png" />
</div>
</div>
</div>
<div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<p>[1]: Bishop, Christopher M. 2006. Pattern Recognition and Machine Learning. Springer.</p>
<p>[2]: M. P. Deisenroth, A. A. Faisal, and C. S. Ong, 2021. <a class="reference external" href="https://mml-book.com">https://mml-book.com</a></p>
<p>[3]: Refer to <a class="reference external" href="https://statisticaloddsandends.wordpress.com/2018/05/24/derivative-of-log-det-x/">https://statisticaloddsandends.wordpress.com/2018/05/24/derivative-of-log-det-x/</a> for an explanation of identity for derivative of log of a matrix determinant</p>
<p>[4]: Horst AM, Hill AP, Gorman KB (2020). palmerpenguins: Palmer Archipelago (Antarctica) penguin data. R package version 0.1.0. <a class="reference external" href="https://allisonhorst.github.io/palmerpenguins/">https://allisonhorst.github.io/palmerpenguins/</a>.</p>
<p>[5]: CSV data downloaded from <a class="reference external" href="https://github.com/mcnakhaee/palmerpenguins">https://github.com/mcnakhaee/palmerpenguins</a></p>
<p>[6]: Code for plotting confidence ellipses from <a class="reference external" href="https://matplotlib.org/3.1.0/gallery/statistics/confidence_ellipse.html">https://matplotlib.org/3.1.0/gallery/statistics/confidence_ellipse.html</a></p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./files\DensityEstimation"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="LaplaceApproximation.html" title="previous page">The Laplace Approximation</a>
    <a class='right-next' id="next-link" href="EMAlgorithm.html" title="next page">Expectation Maximization</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Chandrasekar Sureshkumar<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../../_static/js/index.d3f166471bb80abb5163.js"></script>


    
  </body>
</html>